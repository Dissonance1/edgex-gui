#!/usr/bin/env python
# Copyright Axelera AI, 2025
# Voyager SDK EdgeX Integration Example (V3 Payload Version)
# Modified to send payloads directly to Core Data (Port 59880)

import os
import sys
import time
import json
import datetime
import requests
import threading
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# --- Environment check ---
if not os.environ.get('AXELERA_FRAMEWORK'):
    sys.exit("Please activate the Axelera environment using: source venv/bin/activate")

from axelera.app import config, display, inf_tracers, logging_utils, statistics, yaml_parser
from axelera.app.stream import create_inference_stream

LOG = logging_utils.getLogger(__name__)
PBAR = "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]"

# --- Load class ID mapping ---
CLASS_MAP_FILE = "/data/voyager-sdk/class_map.json"
EMBEDDING_MAP = {}

if os.path.exists(CLASS_MAP_FILE):
    with open(CLASS_MAP_FILE, "r") as f:
        EMBEDDING_MAP = json.load(f)
    print(f"âœ… Loaded class ID mapping from {CLASS_MAP_FILE}")
else:
    print(f"âš ï¸ Class map file not found at {CLASS_MAP_FILE}. Names default to 'unknown'.")

# Updated confidence threshold to 60.0 per previous requirement
CONFIDENCE_THRESHOLD = 60.0
SEND_EXECUTOR = ThreadPoolExecutor(max_workers=8)

# ------------------------------------------------------------------
#                   ENDPOINT DEFINITIONS (ONLY EDGEX)
# ------------------------------------------------------------------

# Connecting directly to EdgeX Core Data (59880) skipping the UI proxy
EDGE_X_EVENT_ENDPOINT = {
    "url": "http://localhost:59880/api/v3/event/device-rest/face_recog/all",      
    "headers": {
        "Content-Type": "application/json",
    }
}

# âœ”ï¸ Send ONLY to EdgeX
ALL_ENDPOINTS = [EDGE_X_EVENT_ENDPOINT]

# ------------------------------------------------------------------
#                       SEND HELPERS
# ------------------------------------------------------------------

def send_payload(payload, url, headers):
    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=5)
        if resp.status_code >= 400:
            print(f"âŒ API Error {resp.status_code}: {resp.text}")
        else:
            print(f"âž¡ï¸  POST {url} â†’ {resp.status_code}")
    except Exception as e:
        print(f"âŒ Send failed ({url}): {e}")

def send_to_all(payload):
    for ep in ALL_ENDPOINTS:
        SEND_EXECUTOR.submit(send_payload, payload, ep["url"], ep["headers"])

# ------------------------------------------------------------------
#                   BUILD EDGEX V3 PAYLOAD
# ------------------------------------------------------------------

def build_v3_payload(device_name, detection_info):
    readings = []

    if "face_count" in detection_info:
        readings.append({
            "resourceName": "face_count",
            "value": str(detection_info["face_count"]),
            "valueType": "Int32"
        })

    if "person_name" in detection_info:
        readings.append({
            "resourceName": "recognized_names",
            "value": detection_info["person_name"],
            "valueType": "String"
        })

    if "confidence" in detection_info:
        readings.append({
            "resourceName": "confidence",
            "value": str(round(float(detection_info["confidence"]), 2)),
            "valueType": "Float32"
        })

    if "bbox_coordinates" in detection_info:
        readings.append({
            "resourceName": "bbox_coordinates",
            "value": json.dumps(detection_info.get("bbox_coordinates", [])),
            "valueType": "String"
        })

    return {
        "apiVersion": "v3",
        "trigger": "inference",
        "readings": readings
    }

# ------------------------------------------------------------------
#            DETECTION METADATA EXTRACTION
# ------------------------------------------------------------------

def extract_detection_data(meta, device_base_name):
    detection_info = {
        "face_count": 0,
        "person_name": "unknown",
        "confidence": 0.0,
        "frame_timestamp": datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
    }

    if not meta or not hasattr(meta, "_meta_map"):
        return detection_info

    detections = getattr(meta._meta_map.get("detections"), "_secondary_metas", {}).get("recognitions", [])
    recognized_names, confidences = [], []

    for recog_meta in detections:
        person_name, confidence, class_id = "unknown", 0.0, None

        if hasattr(recog_meta, "_class_ids") and recog_meta._class_ids:
            class_id = str(int(recog_meta._class_ids[0][0]))

        if hasattr(recog_meta, "_scores") and recog_meta._scores:
            confidence = float(recog_meta._scores[0][0]) * 100.0

        if confidence >= CONFIDENCE_THRESHOLD and class_id in EMBEDDING_MAP:
            person_name = EMBEDDING_MAP[class_id]
        else:
            person_name = "unknown"

        recognized_names.append(person_name)
        confidences.append(confidence)

    detection_info.update({
        "face_count": len(recognized_names),
        "person_name": ",".join(recognized_names) if recognized_names else "unknown",
        "confidence": max(confidences) if confidences else 0.0,
    })

    return detection_info

# ------------------------------------------------------------------
#                     INFERENCE LOOP
# ------------------------------------------------------------------

def inference_loop(args, log_file_path, stream, app, wnd, tracers=None):
    device_base_name = "FaceDetector_2cf7f12052608e69_"
    last_seen = {}
    last_sent_state = set()
    REAPPEAR_TIMEOUT = 5.0

    for frame_result in tqdm(stream, desc="Detecting...", unit="frames", leave=False, bar_format=PBAR):
        image, meta = frame_result.image, frame_result.meta

        if image:
            wnd.show(image, meta, frame_result.stream_id)

        if wnd.is_closed:
            break

        if not meta:
            continue

        detection_info = extract_detection_data(meta, device_base_name)
        current_people = set(detection_info["person_name"].split(",")) if detection_info["person_name"] else set()
        now = time.time()

        expired = {p for p, t in last_seen.items() if now - t > REAPPEAR_TIMEOUT}

        for p in expired:
            last_seen.pop(p, None)
            if p in last_sent_state:
                last_sent_state.remove(p)

        for person in current_people:
            last_seen[person] = now

        new_people = {p for p in current_people if p not in last_sent_state}

        if new_people:
            print(f"ðŸ“¡ Sending event for: {new_people}")
            last_sent_state |= new_people

            payload = build_v3_payload(device_base_name, detection_info)
            if detection_info["face_count"] > 0:
                send_to_all(payload)

# ------------------------------------------------------------------
#                            MAIN
# ------------------------------------------------------------------

if __name__ == "__main__":
    network_yaml_info = yaml_parser.get_network_yaml_info()
    parser = config.create_inference_argparser(
        network_yaml_info,
        description="Voyager SDK Inference â†’ EdgeX Integration (V3 Direct)"
    )
    parser.add_argument("--save-tracers", type=str, default=None)
    args = parser.parse_args()
    tracers = inf_tracers.create_tracers_from_args(args)

    try:
        log_file, log_file_path = None, None
        if args.show_stats:
            log_file, log_file_path = statistics.initialise_logging()

        stream = create_inference_stream(
            config.SystemConfig.from_parsed_args(args),
            config.InferenceStreamConfig.from_parsed_args(args),
            config.PipelineConfig.from_parsed_args(args),
            config.LoggingConfig.from_parsed_args(args),
            config.DeployConfig.from_parsed_args(args),
            tracers=tracers,
        )

        with display.App(
            visible=args.display,
            opengl=stream.hardware_caps.opengl,
            buffering=not stream.is_single_image(),
        ) as app:
            wnd = app.create_window("Inference demo", size=args.window_size)
            app.start_thread(inference_loop, (args, log_file_path, stream, app, wnd, tracers), name="InferenceThread")
            app.run(interval=1 / 10)

    except KeyboardInterrupt:
        LOG.exit_with_error_log()
    except logging_utils.UserError as e:
        LOG.exit_with_error_log(e.format())
    except Exception as e:
        LOG.exit_with_error_log(e)
    finally:
        if "stream" in locals():
            stream.stop()
        time.sleep(3)
        SEND_EXECUTOR.shutdown(wait=True)
