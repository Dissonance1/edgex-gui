#!/usr/bin/env python
# Copyright Axelera AI, 2025
# Voyager SDK EdgeX Integration Example (Proxy Version)

import os
import sys
import time
import json
import datetime
import requests
import threading
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# --- Environment check ---
if not os.environ.get('AXELERA_FRAMEWORK'):
    sys.exit("Please activate the Axelera environment using: source venv/bin/activate")

from axelera.app import config, display, inf_tracers, logging_utils, statistics, yaml_parser
from axelera.app.stream import create_inference_stream

LOG = logging_utils.getLogger(__name__)
PBAR = "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]"

# --- Load class ID mapping ---
CLASS_MAP_FILE = "/data/voyager-sdk/class_map.json"
EMBEDDING_MAP = {}

if os.path.exists(CLASS_MAP_FILE):
    with open(CLASS_MAP_FILE, "r") as f:
        EMBEDDING_MAP = json.load(f)
    print(f"âœ… Loaded class ID mapping")

CONFIDENCE_THRESHOLD = 60.0
SEND_EXECUTOR = ThreadPoolExecutor(max_workers=8)

# ------------------------------------------------------------------
#                   ENDPOINT DEFINITIONS
# ------------------------------------------------------------------

# RESTORED TO PROXY URL (Port 4000)
EDGE_X_EVENT_ENDPOINT = {
    "url": "http://localhost:4000/core-data/api/v3/event/face_recog/_Face-recog/all",      
    "headers": {
        "Content-Type": "application/json",
    }
}

ALL_ENDPOINTS = [EDGE_X_EVENT_ENDPOINT]

def send_payload(payload, url, headers):
    try:
        resp = requests.post(url, json=payload, headers=headers, timeout=5)
        print(f"âž¡ï¸  POST {url} â†’ {resp.status_code}")
    except Exception as e:
        print(f"âŒ Send failed: {e}")

def send_to_all(payload):
    for ep in ALL_ENDPOINTS:
        SEND_EXECUTOR.submit(send_payload, payload, ep["url"], ep["headers"])

def build_v3_payload(info):
    readings = []
    if "face_count" in info:
        readings.append({"resourceName": "face_count", "value": str(info["face_count"]), "valueType": "Int32"})
    if "person_name" in info:
        readings.append({"resourceName": "recognized_names", "value": info["person_name"], "valueType": "String"})
    if "confidence" in info:
        readings.append({"resourceName": "confidence", "value": str(round(float(info["confidence"]), 2)), "valueType": "Float32"})
    
    return {
        "apiVersion": "v3",
        "trigger": "inference",
        "origin": int(time.time() * 1e9),
        "readings": readings
    }

def extract_detection_data(meta):
    detection_info = {"face_count": 0, "person_name": "unknown", "confidence": 0.0}
    if not meta or not hasattr(meta, "_meta_map"): return detection_info
    detections = getattr(meta._meta_map.get("detections"), "_secondary_metas", {}).get("recognitions", [])
    recognized_names, confidences = [], []
    for recog_meta in detections:
        person_name, confidence, class_id = "unknown", 0.0, None
        if hasattr(recog_meta, "_class_ids") and recog_meta._class_ids:
            class_id = str(int(recog_meta._class_ids[0][0]))
        if hasattr(recog_meta, "_scores") and recog_meta._scores:
            confidence = float(recog_meta._scores[0][0]) * 100.0
        if confidence >= CONFIDENCE_THRESHOLD and class_id in EMBEDDING_MAP:
            person_name = EMBEDDING_MAP[class_id]
        recognized_names.append(person_name)
        confidences.append(confidence)
    detection_info.update({"face_count": len(recognized_names), "person_name": ",".join(recognized_names) if recognized_names else "unknown", "confidence": max(confidences) if confidences else 0.0})
    return detection_info

def inference_loop(args, log_file_path, stream, app, wnd, tracers=None):
    last_seen, last_sent_state = {}, set()
    REAPPEAR_TIMEOUT = 5.0
    for frame_result in tqdm(stream, desc="Detecting...", unit="frames", leave=False, bar_format=PBAR):
        image, meta = frame_result.image, frame_result.meta
        if image: wnd.show(image, meta, frame_result.stream_id)
        if wnd.is_closed or not meta: continue
        detection_info = extract_detection_data(meta)
        current_people = set(detection_info["person_name"].split(",")) if detection_info["person_name"] else set()
        now = time.time()
        for p in {p for p, t in last_seen.items() if now - t > REAPPEAR_TIMEOUT}:
            last_seen.pop(p, None)
            if p in last_sent_state: last_sent_state.remove(p)
        for person in current_people: last_seen[person] = now
        new_people = current_people - last_sent_state
        if new_people:
            print(f"ðŸ“¡ Sending event for: {new_people}")
            last_sent_state |= new_people
            if detection_info["face_count"] > 0:
                send_to_all(build_v3_payload(detection_info))

if __name__ == "__main__":
    parser = config.create_inference_argparser(yaml_parser.get_network_yaml_info())
    parser.add_argument("--save-tracers", type=str, default=None)
    args = parser.parse_args()
    try:
        stream = create_inference_stream(config.SystemConfig.from_parsed_args(args), config.InferenceStreamConfig.from_parsed_args(args), config.PipelineConfig.from_parsed_args(args), config.LoggingConfig.from_parsed_args(args), config.DeployConfig.from_parsed_args(args))
        with display.App(visible=args.display, opengl=stream.hardware_caps.opengl, buffering=not stream.is_single_image()) as app:
            wnd = app.create_window("Inference", size=args.window_size)
            app.start_thread(inference_loop, (args, None, stream, app, wnd), name="InfThread")
            app.run(interval=1 / 10)
    finally:
        if "stream" in locals(): stream.stop()
        SEND_EXECUTOR.shutdown(wait=True)
